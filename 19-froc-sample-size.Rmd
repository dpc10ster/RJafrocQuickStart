# (PART\*) FROC sample size {-}


# FROC sample size estimation {#froc-sample-size}


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(kableExtra)
library(seqinr)
library(RJafroc)
library(ggplot2)
library(gridExtra)
library(binom)
library(here)
```


## How much finished 80 percent {#froc-sample-size-how-much-finished}



## Overview

This chapter is split into two parts: 

* The first part details a step-by-step approach to FROC paradigm sample size estimation; 

* The second part encapsulates most of the details in a function `SsFrocNhRsmModel()`.



## Part 1

### Introduction {#froc-sample-size-intro}

FROC sample size estimation is not fundamentally different from the procedure outlined in TBA Chapter 11 for the ROC paradigm. 

To recapitulate, based on analysis of a pilot ROC dataset and using a specified FOM, e.g., `FOM = Wilcoxon`, and either `method = "DBM"` or `method = "OR"` for significance testing, one estimates the intrinsic variability of the data expressed in terms of FOM variance components ^[For the DBM method these are the pseudovalue variance components while for OR method these are the FOM treatment-reader variance component and the FOM covariances.]. The second step is to specify a clinically realistic effect-size, e.g., the anticipated AUC difference between the two modalities - and herein lies a temptation to inflate this value, thereby guaranteeing adequate sample size even with few readers and cases and large variability. 

Given the variance components the sample size functions implemented in `RJafroc` (function names beginning with `Ss`) allow one to estimate the number of readers and cases necessary to detect (i.e., reject the null hypothesis) the modality AUC difference with probability no smaller than the Type II error rate $\beta$, typically chosen to be 20 percent - corresponding to at least 80 percent statistical power - while controlling the Type I error rate to no greater than $\alpha$, typically chosen to be 5 percent. 

>The preceding sentence may be confusing. One can always detect even a very small effect size by always rejecting the NH. However this would imply that almost identical treatments would always be declared different thereby increasing the NH rejection rate to 100 percent. Therefore it is important to control the NH rejection rate at a reasonably low level (e.g., 5 percent) while still maintaining the AG rejection rate at a reasonably high level (e.g., 80 percent).


In FROC analysis the only difference, indeed the critical difference, is the choice of FOM; e.g., `FOM = "wAFROC"` instead of the inferred ROC-AUC, `FOM = "HrAuc"`. The FROC dataset is analyzed using either the DBM (or the OR) method. This yields the necessary variance components (or the covariance matrix) corresponding to the wAFROC-AUC. The next step is to specify the effect-size **in wAFROC-AUC units** and this requires care. The ROC-AUC has a historically well-known interpretation, namely it is the classification ability at separating diseased patients from non-diseased patients, while the wAFROC-AUC does not. Needed is a way of relating the effect-size in easily understood ROC-AUC units to one in wAFROC-AUC units. This requires a physical model, e.g., the RSM, that predicts both ROC and wAFROC curves and their corresponding AUCs.


1.	One chooses an ROC-AUC effect-size that is realistic, one that clinicians understand and can therefore participate in, in the effect-size postulation process. Lacking such information I recommend, based on past ROC studies, 0.03 as typical of a small effect size and 0.05 as typical of a moderate effect size.
2.	One converts the ROC effect-size to a wAFROC-AUC effect-size using the method described in the next section.
3.	One uses the sample size tools in in `RJafroc` to determine sample size or power. 


>**It is important to recognize is that all quantities have to be in the same units**. When performing ROC analysis, everything (variance components and effect-size) has to be in units of the selected FOM, e.g., `FOM = "Wilcoxon"`. When doing wAFROC analysis, everything has to be in units of the wAFROC-AUC, i.e., `FOM = "wAFROC"`. The variance components and effect-size in wAFROC-AUC units will be different from their corresponding ROC counterparts. In particular, as shown next, an ROC-AUC effect-size of 0.05 generally corresponds to a larger effect-size in wAFROC-AUC units. The reason for this is that the range over which wAFROC-AUC can vary, namely 0 to 1, is twice the corresponding ROC-AUC range (0.5 to 1). For the same reason the wAFROC variance components also tend to be larger than the ROC variance components.


The next section explains the steps used to implement #2 above. 

### Relating an ROC effect-size to a wAFROC effect-size

* This chapter uses the *first two* treatments of `dataset04` as defining the NH. This is a 5 treatment, 4 radiologist and 200 case FROC dataset [@zanca2009evaluation] which was acquired on a 5-point scale, i.e., it is already binned. If not one needs to bin the dataset using `DfBinDataset()` before RSM fitting can be performed. 

* If the data uses continuous ratings one bins it as follows using `rocDatasetB <- DfBinDataset(rocDataset, opChType = "ROC")`. The default number of bins should be used. Unlike binning using arbitrarily set thresholds the thresholds found by `DfBinDataset()` are unique as they maximize ROC-AUC. 

* If there are more than two treatments in the pilot dataset, `dataset04`, one extracts those treatments that represent "almost" null hypothesis data (in the sense of similar ROC-AUCs). For example `datasetNH <- DfExtractDataset(dataset, trts = c(1,2))` extracts treatments 1 and 2. More than two treatments can be used if they have similar AUCs as the median finding procedure described below benefits from more data. However, the final sample size predictions are restricted to two treatments in the pivotal study.

* The reason for using RSM parameter values only for the first two treatments is that these were found [@zanca2009evaluation] to be almost equivalent (more precisely, the NH could not be rejected for the first two treatments) so it makes sense to regard them as "almost" NH treatments.

* If the original data is FROC, convert it to ROC using `rocDatasetNH <- DfFroc2Roc(datasetNH)`: this is because **the RSM only fits binned ROC data**.

* For each treatment and reader the ROC data is fitted by `FitRsmRoc()`, see example below, yielding estimates of the RSM *physical* parameters $\mu, \lambda, \nu$ (not the *intrinsic* values $\mu, \lambda', \nu'$). See Chapter TBA for the distinction between physical and intrinsic parameters.  

* The following code block defines the pilot FROC data `frocDataNH` and `rocDataNH`. The latter is the highest-rating ROC dataset inferred from the FROC dataset using `DfFroc2Roc()`.

```{r}
frocDataNH <- DfExtractDataset(dataset04, trts = c(1,2))
rocDataNH <- DfFroc2Roc(frocDataNH)
# Following line is unnecessary as the data is already binned
rocDataBinNH <- DfBinDataset(rocDataNH, opChType = "ROC")
# but it cant hurt
```


The next code block determines `lesDistr`, the lesion distribution dataframe, see Section TBA, as the RSM fitting algorithm needs to know how lesion-rich the dataset is: the predicted ROC-AUC depends on the lesion-richness of the dataset. 

TBA For reasons that will become clear below, one also needs the distribution of the lesion weights.

```{r}
lesDistr <- UtilLesDistr(frocDataNH)
lesDistr
```


Note that `lesDistr` is determined from the FROC NH dataset as lesion distribution information is lost upon conversion to an ROC dataset. 


For this dataset `Lmax` is 3, and fraction `r lesDistr$Freq[1]` of diseased cases have one lesion, fraction `r lesDistr$Freq[2]` of diseased cases have two lesions and fraction `r lesDistr$Freq[3]` of diseased cases have three lesions. The `PlotRsmOperatingCharacteristics` function used below sets `relWeights = 0` ensuring equally weighted lesions. 


The next code block determines the number of treatments and readers (`I` and `J`) from the dimensions of the `frocDataNH$ratings$NL` array (lines 1 and 2). It creates (line 3) an array `RsmParmsNH` to hold the RSM fitted NH parameters. For each treatment and reader it applies the fitting algorithm `FitRsmRoc()` (lines 4 - 11). The first three returned values are `mu`, `lambda` and `nu`, corresponding to the physical RSM parameters ${\mu}$, ${\lambda}$ and ${\nu}$.

```{r, attr.source = ".numberLines"}
I <- dim(frocDataNH$ratings$NL)[1]
J <- dim(frocDataNH$ratings$NL)[2]
RsmParmsNH <- array(dim = c(I,J,3))
for (i in 1:I) {
  for (j in 1:J)  {
    x1 <- FitRsmRoc(rocDataBinNH, trt = i, rdr = j, lesDistr$Freq)
    RsmParmsNH[i,j,1] <- x1[[1]] # mu
    RsmParmsNH[i,j,2] <- x1[[2]] # lambda
    RsmParmsNH[i,j,3] <- x1[[3]] # nu
  }
}
```


I recommend taking the median (not the mean) of each of the parameters, over all treatment-reader indices, as representing the "average" NH dataset. The median is less sensitive to outliers than the mean.  


```{r}
muNH <- median(RsmParmsNH[,,1]) 
lambdaNH <- median(RsmParmsNH[,,2])
nuNH <- median(RsmParmsNH[,,3])
```


The defining values of the fitting model are `muNH` = `r muNH`, `lambdaNH` = `r lambdaNH` and `nuNH` = `r nuNH`. These obey the constraints `lambdaNH > 0` and `0 < nuNH < 1`. 

We are now ready to calculate the expected NH FOMs using the ROC-AUC and the wAFROC-AUC (these depend on the lesion distribution and the weights).  

```{r}
aucRocNH <- PlotRsmOperatingCharacteristics(
  muNH, lambdaNH, nuNH, 
  lesDistr = lesDistr$Freq, OpChType = "ROC")$aucROC
aucwAfrocNH <- PlotRsmOperatingCharacteristics(
  muNH, lambdaNH, nuNH, 
  lesDistr = lesDistr$Freq, OpChType = "wAFROC")$aucwAFROC
```


* The plotting function `PlotRsmOperatingCharacteristics()` returns a number of other objects, most importantly the plot, but here we use only the AUC, which is obtained by numerical integration of the predicted operating characteristic. 

* One has `aucRocNH = `r aucRocNH`` and `aucwAfrocNH = `r aucwAfrocNH``. Note that the wAFROC-FOM is smaller than the ROC-FOM as it includes the localization constraint. 

* To induce the alternative hypothesis condition, one increments $\mu_{NH}$ by $\Delta_{\mu}$. The resulting ROC-AUC and wAFROC-AUC are calculated, again by numerical integration of the RSM predicted ROC and wAFROC curves.

* The next step is to calculate the effect size (AH value minus NH value) using ROC and wAFROC FOMs for a series of specified `deltaMu` values. This generates values that can be used to interpolate the wAFROC effect size for a specified ROC effect size. 


```{r, echo=FALSE}
deltaMu <- seq(0.01, 0.2, 0.01) # values of deltaMu to scan below
esRoc <- array(dim = length(deltaMu));eswAfroc <- array(dim = length(deltaMu))
for (i in 1:length(deltaMu)) {
  esRoc[i] <- PlotRsmOperatingCharacteristics(
    muNH + deltaMu[i], lambdaNH, nuNH, lesDistr = lesDistr$Freq, OpChType = "ROC")$aucROC - aucRocNH
  eswAfroc[i] <- PlotRsmOperatingCharacteristics(
    muNH+ deltaMu[i], lambdaNH, nuNH, lesDistr = lesDistr$Freq, OpChType = "wAFROC")$aucwAFROC - aucwAfrocNH
  #cat("ES_ROC = ", esRoc[i], ", ES_wAFROC = ", eswAfroc[i],"\n")
}
```

Here is a plot of wAFROC effect size (y-axis) vs. ROC effect size.


```{r, fig.show='hold', fig.align='center'}
df <- data.frame(es_ROC = esRoc, es_wAFROC = eswAfroc)
p <- ggplot(data = df, aes(x = es_ROC, y = es_wAFROC)) +
  geom_smooth(method = "lm", se = FALSE, color = "black", formula = y ~ x) +
  geom_point(size = 4) +
  scale_color_manual(values = "black") + 
  theme(axis.title.y = element_text(size = 10,face="bold"),
        axis.title.x = element_text(size = 10,face="bold")) +
  scale_x_continuous(expand = c(0, 0)) + 
  scale_y_continuous(expand = c(0, 0)) 
print(p)
```             

The plot is linear and the intercept is close to zero. This makes it easy to implement an interpolation function. In the following code block the first line fits `eswAfroc` vs. `esRoc` using the linear model `lm()` function constrained to pass through the origin (the minus one): `scaleFactor <- lm(eswAfroc ~ -1 + esRoc)`. One expects this constraint since for `deltaMu = 0` the effect size must be zero no matter how it is measured. 

```{r}
scaleFactor<-lm(eswAfroc~-1+esRoc) # fit values to straight line thru origin
effectSizeROC <- seq(0.01, 0.1, 0.01)
effectSizewAFROC <- effectSizeROC*scaleFactor$coefficients[1] # r2 = summary(scaleFactor)$r.squared
```


The slope of the zero-intercept constrained straight line fit is `scaleFactor` = `r scaleFactor$coefficients[1]` and the squared correlation coefficient is `R2` = `r summary(scaleFactor)$r.squared`. Therefore, the conversion from ROC to wAFROC effect size is: `effectSizewAFROC = scaleFactor * effectSizeROC`. **The wAFROC effect size is 1.26 times the ROC effect size.** 


It remains to calculate the variance components using the two FOMs.


### Computing variance components

The code block applies `StSignificanceTesting()` to `rocDataNH` and `frocDataNH`, using the appropriate FOM, and extracts the variance components `varComp_roc` and `varComp_afroc`.

```{r}
temp1 <- StSignificanceTesting(rocDataNH, FOM = "Wilcoxon", method = "DBM", analysisOption = "RRRC")
temp2 <- StSignificanceTesting(frocDataNH, FOM = "wAFROC", method = "DBM", analysisOption = "RRRC")
varComp_roc <- temp1$ANOVA$VarCom
varComp_afroc <- temp2$ANOVA$VarCom
```


The observed wAFROC effect-size (on the pilot dataset) is `r temp2$RRRC$ciDiffTrt$Estimate`. This is a very small effect size as it represent the "almost" NH condition; the corresponding ROC effect-size is also small: `r temp1$RRRC$ciDiffTrt$Estimate`. These are not surprising that the study [@zanca2009evaluation] did not find a significant difference between these two treatments

The respective variance components are:


```{r}
print(varComp_roc)
print(varComp_afroc)
```


Only terms involving treatment are relevant to sample size. The wAFROC TC variance component, `r varComp_afroc$varTC`, and the error variance component, `r varComp_afroc$varErr`; these values are slightly larger than the corresponding ROC ones: `r varComp_roc$varTC` and `r varComp_roc$varErr`, as expected because the range of the wAFROC FOM is twice that of the ROC FOM. 


### Comparing ROC power to wAFROC power for equivalent effect-sizes

We are now ready to compare ROC and wAFROC powers for equivalent effect sizes. The following example is for 5 readers (`JPivot`) and 100 cases (`KPivot`) in the **pivotal study**. 


```{r}
power_roc <- array(dim = length(effectSizeROC))
power_afroc <- array(dim = length(effectSizeROC))

JPivot <- 5;KPivot <- 100
for (i in 1:length(effectSizeROC)) {
  
  # these are pseudovalue based variance components assuming FOM = "Wilcoxon
  varYTR_roc <- varComp_roc["VarTR","Estimates"]
  varYTC_roc <- varComp_roc["VarTC","Estimates"]
  varYEps_roc <- varComp_roc["VarErr","Estimates"]
  
  ret <- SsPowerGivenJK(
    dataset = NULL, 
    FOM = "Wilcoxon", 
    J = JPivot, 
    K = KPivot, 
    analysisOption = "RRRC", 
    effectSize = effectSizeROC[i], 
    method = "DBM", 
    LegacyCode = TRUE, 
    list(VarTR = varYTR_roc, VarTC = varYTC_roc, VarErr = varYEps_roc))
  power_roc[i] <- ret$powerRRRC
  
  # these are pseudovalue based variance components assuming FOM = "wAFROC"
  varYTR_afroc <- varComp_afroc["VarTR","Estimates"]
  varYTC_afroc <- varComp_afroc["VarTC","Estimates"]
  varYEps_afroc <- varComp_afroc["VarErr","Estimates"]
  
  ret <- SsPowerGivenJK(
    dataset = NULL, 
    FOM = "Wilcoxon", 
    J = JPivot, 
    K = KPivot, 
    analysisOption = "RRRC", 
    effectSize = effectSizewAFROC[i], 
    method = "DBM", 
    LegacyCode = TRUE, 
    list(VarTR = varYTR_afroc, VarTC = varYTC_afroc, VarErr = varYEps_afroc))
  power_afroc[i] <- ret$powerRRRC
  
  cat("ROC-ES = ", effectSizeROC[i], 
      ", wAFROC-ES = ", effectSizewAFROC[i], 
      ", Power-ROC = ", power_roc[i], 
      ", Power-wAFROC = ", power_afroc[i], "\n")
}
```


Since the wAFROC effect size is 1.26 times the ROC effect size, wAFROC power is larger than that for ROC. The effect is magnified as the effect size enters as the square in the formula for the power (this overwhelms the slight increase, noted previously, in variability of wAFROC-FOM relative to ROC-FOM). The following is a plot of the respective powers.


```{r, echo=FALSE, fig.show='hold', fig.align='center'}
df <- data.frame(power_ROC = power_roc, power_wAFROC = power_afroc)
p <- ggplot(mapping = aes(x = power_ROC, y = power_wAFROC)) +
  geom_line(data = df, linewidth = 2)+
  scale_color_manual(values = "black") + 
  theme(axis.title.y = element_text(size = 10,face="bold"),
        axis.title.x = element_text(size = 10,face="bold"))  +
  scale_x_continuous(expand = c(0, 0)) + 
  scale_y_continuous(expand = c(0, 0))
print(p)
```             





## Part 2


### Introduction

This example uses the FED dataset as a pilot FROC study and function `SsFrocNhRsmModel()` to construct the NH model (encapsulating some of the code in the first part).


### Constructing the NH model for the dataset

One starts by extracting the first two treatments from `dataset04`, which represent the NH dataset, see previous part. Next one constructs the NH model - note that the lesion distribution `lesDistr` can be specified here independently of that in the pilot dataset. This allows some control over selection of the diseased cases in the pivotal study.

```{r} 
lesDistr <- c(0.69, 0.20, 0.11) # sic!
frocNhData <- DfExtractDataset(dataset04, trts = c(1,2))
lesDistr <- UtilLesDistr(lesDistr) # sic!
ret <- SsFrocNhRsmModel(frocNhData, lesDistr = lesDistr$Freq)
muNH <- ret$mu
lambdaNH <- ret$lambda
nuNH <- ret$nu
scaleFactor <- ret$scaleFactor
```


The fitting model is defined by `muNH` = `r muNH`,  `lambdaNH` = `r lambdaNH`  and  `nuNH` = `r nuNH` and `lesDistr$Freq` = `r lesDistr$Freq`. The effect size scale factor is `scaleFactor` = `r scaleFactor`. All of these values are consistent with the Part I values.


```{r}
aucRocNH <- PlotRsmOperatingCharacteristics(
  muNH, lambdaNH, nuNH, 
  lesDistr = lesDistr$Freq, 
  OpChType = "ROC")$aucROC

aucwAfrocNH <- PlotRsmOperatingCharacteristics(
  muNH, lambdaNH, nuNH, 
  lesDistr = lesDistr$Freq, 
  OpChType = "wAFROC")$aucwAFROC
```

The null hypothesis ROC AUC is `r aucRocNH` and the corresponding NH wAFROC AUC is `r aucwAfrocNH`. 

### Extracting the wAFROC variance components

The next code block applies `StSignificanceTesting()` to `frocNhData`, using `FOM = "wAFROC"` and extracts the variance components.

```{r}
varComp_afroc  <- StSignificanceTesting(
  frocNhData, FOM = "wAFROC", method = "DBM", 
  analysisOption = "RRRC")$ANOVA$VarCom
```


### wAFROC power for specified ROC effect size, number of readers J and number of cases K

The following example is for ROC effect size = 0.05, 5 readers (`J = 5`) and 100 cases (`K = 100`) in the **pivotal study**. 


```{r}
ROC_ES <- 0.05
effectSizewAFROC <- scaleFactor * ROC_ES
J <- 5;K <- 100

varYTR_afroc <- varComp_afroc["VarTR","Estimates"] 
varYTC_afroc <- varComp_afroc["VarTC","Estimates"]
varYEps_afroc <- varComp_afroc["VarErr","Estimates"]
ret <- SsPowerGivenJK(
  dataset = NULL, FOM = "Wilcoxon", J = J, K = K, analysisOption = "RRRC", 
  effectSize = effectSizewAFROC, method = "DBM", LegacyCode = TRUE, 
  list(VarTR = varYTR_afroc,
  VarTC = varYTC_afroc,
  VarErr = varYEps_afroc))
power_afroc <- ret$powerRRRC

cat("ROC-ES = ", ROC_ES, 
    ", wAFROC-ES = ", ROC_ES * scaleFactor, 
    ", Power-wAFROC = ", power_afroc, "\n")
```


### wAFROC number of cases for 80 percent power for a given number of readers J


```{r}
VarTR_afroc <- varComp_afroc["VarTR","Estimates"] 
VarTC_afroc <- varComp_afroc["VarTC","Estimates"]
VarErr_afroc <- varComp_afroc["VarErr","Estimates"]
ret2 <- SsSampleSizeKGivenJ(
  dataset = NULL, J = 6, 
  effectSize = effectSizewAFROC, 
  method = "DBM", LegacyCode = TRUE,
  list(VarTR = VarTR_afroc, VarTC = VarTC_afroc, VarErr = VarErr_afroc))

cat("ROC-ES = ", ROC_ES, 
    ", wAFROC-ES = ", ROC_ES * scaleFactor, 
    ", K80RRRC = ", ret2$KRRRC, 
    ", Power-wAFROC = ", ret2$powerRRRC, "\n")
```


### wAFROC-FOM power for a given number of readers J and cases K


```{r}

ret3 <- SsPowerGivenJK(
  dataset = NULL, J = 6, 
  K = ret2$KRRRC, 
  effectSize = effectSizewAFROC, 
  method = "DBM", LegacyCode = TRUE,
  list(VarTR = VarTR_afroc, VarTC = VarTC_afroc, VarErr = VarErr_afroc))

cat("ROC-ES = ", ROC_ES, 
    ", wAFROC-ES = ", ROC_ES * scaleFactor, 
    ", powerRRRC = ", ret3$powerRRRC, "\n")
```


The estimated power is close to 80 percent as the number of cases (`ret2$KRRRC = `r ret2$KRRRC``) was chosen deliberately from the previous code block.




